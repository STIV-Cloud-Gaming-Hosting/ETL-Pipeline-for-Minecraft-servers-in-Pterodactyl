{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline Pterodactyl Resource Consumption\n",
    "\n",
    "### Index\n",
    "\n",
    "- Install requierements\n",
    "- Import libraries and setup key variables\n",
    "- Define functions\n",
    "- Get Pterodactyl Utilization Information\n",
    "- Load data into the Postgres database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requierements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and setup key variables\n",
    "Remember to add you own credentials in the .env file for them to be loaded here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "from sqlalchemy import create_engine, text\n",
    "from pydactyl import PterodactylClient\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Load .env file credentials\n",
    "load_dotenv()\n",
    "\n",
    "# Database connection\n",
    "host = os.getenv('POSTGRES_HOST')\n",
    "port = os.getenv('POSTGRES_PORT')\n",
    "database = os.getenv('POSTGRES_DATABASE')\n",
    "username = os.getenv('POSTGRES_USERNAME')\n",
    "password = os.getenv('POSTGRES_PASSWORD')\n",
    "connection = f'postgresql://{username}:{password}@{host}:{port}/{database}'\n",
    "\n",
    "# Pterodactyl connection\n",
    "pterodactyl_url = os.getenv('PTERODACTYL_URL')\n",
    "application_api_key = os.getenv('PTERODACTYL_APP_KEY')\n",
    "client_api_key = os.getenv('PTERODACTYL_CLI_KEY')\n",
    "\n",
    "# Connecto to Pterodactyl Application API\n",
    "api_app = PterodactylClient(pterodactyl_url, application_api_key, debug=False)\n",
    "# Connecto to Pterodactyl Client API\n",
    "api_cli = PterodactylClient(pterodactyl_url, client_api_key, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform from bytes to megabytes\n",
    "from functions import bytes_to_megabytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pterodactyl Utilization Information\n",
    "About: current state, memory bytes, cpu absolute, disk bytes, network rx/tx bytes, uptime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020062923431396484\n",
      "39.03044056892395\n",
      "   server_identifier  status     ram_mean  ram_std      ram_min      ram_max  \\\n",
      "0           1a76c940    True  1697.136719      NaN  1697.136719  1697.136719   \n",
      "1           1d3ffc65   False     0.000000      NaN     0.000000     0.000000   \n",
      "2           3299f0f0   False     0.000000      NaN     0.000000     0.000000   \n",
      "3           453f605d   False     0.000000      NaN     0.000000     0.000000   \n",
      "4           45f311a5   False     0.000000      NaN     0.000000     0.000000   \n",
      "5           4f125f52   False     0.000000      NaN     0.000000     0.000000   \n",
      "6           7cc366dc   False     0.000000      NaN     0.000000     0.000000   \n",
      "7           9c032ee0    True  1634.957031      NaN  1634.957031  1634.957031   \n",
      "8           9e053c46   False     0.000000      NaN     0.000000     0.000000   \n",
      "9           b1109534   False     0.000000      NaN     0.000000     0.000000   \n",
      "10          cce22b85   False     0.000000      NaN     0.000000     0.000000   \n",
      "\n",
      "    cpu_mean  cpu_std  cpu_min  cpu_max    disk_mean  disk_std     disk_min  \\\n",
      "0     57.404      NaN   57.404   57.404  2538.266317       NaN  2538.266317   \n",
      "1      0.000      NaN    0.000    0.000   145.036242       NaN   145.036242   \n",
      "2      0.000      NaN    0.000    0.000     0.000245       NaN     0.000245   \n",
      "3      0.000      NaN    0.000    0.000   109.983271       NaN   109.983271   \n",
      "4      0.000      NaN    0.000    0.000    19.398968       NaN    19.398968   \n",
      "5      0.000      NaN    0.000    0.000   115.204850       NaN   115.204850   \n",
      "6      0.000      NaN    0.000    0.000   228.219181       NaN   228.219181   \n",
      "7      8.418      NaN    8.418    8.418   197.376982       NaN   197.376982   \n",
      "8      0.000      NaN    0.000    0.000  6122.262032       NaN  6122.262032   \n",
      "9      0.000      NaN    0.000    0.000   947.253014       NaN   947.253014   \n",
      "10     0.000      NaN    0.000    0.000   184.773327       NaN   184.773327   \n",
      "\n",
      "       disk_max         capture_time  \n",
      "0   2538.266317  2024-02-12 20:06:34  \n",
      "1    145.036242  2024-02-12 20:06:34  \n",
      "2      0.000245  2024-02-12 20:06:34  \n",
      "3    109.983271  2024-02-12 20:06:34  \n",
      "4     19.398968  2024-02-12 20:06:34  \n",
      "5    115.204850  2024-02-12 20:06:34  \n",
      "6    228.219181  2024-02-12 20:06:34  \n",
      "7    197.376982  2024-02-12 20:06:34  \n",
      "8   6122.262032  2024-02-12 20:06:34  \n",
      "9    947.253014  2024-02-12 20:06:34  \n",
      "10   184.773327  2024-02-12 20:06:34  \n"
     ]
    }
   ],
   "source": [
    "# Setting variables\n",
    "SCHEMA = 'pterodactyl'\n",
    "WINDOW_EXTRACTION_TIME = 30 # the time window in which it recieves data from the servers [seconds]\n",
    "BREAK_TIME = 10 # the time it takes to rest after getting data from all servers [seconds]\n",
    "WAITING_TIME = 1 # the time it takes to rest after getting date from each server [seconds]\n",
    "\n",
    "# Define the schema and extrat all uuid from every server from postgres\n",
    "engine = create_engine(connection)\n",
    "with engine.connect() as conn:\n",
    "    list_of_uuid = conn.execute(text(f'SELECT servers.uuid FROM {SCHEMA}.servers  WHERE servers.is_active = true'))\n",
    "    result = list_of_uuid.fetchall()\n",
    "    list_servers = [uuid for uuid, in result] #remove the tuples of uuid from results\n",
    "\n",
    "# Extract the data from every uuid in the postgres database\n",
    "all_utilizations = []\n",
    "start_time = time.time()\n",
    "while (time.time() - start_time) < WINDOW_EXTRACTION_TIME:\n",
    "    print(time.time() - start_time)\n",
    "    for server in list_servers:\n",
    "        try:\n",
    "            consumption = api_cli.client.servers.get_server_utilization(server)\n",
    "            consumption.update({'identifier': server[:8]})\n",
    "            all_utilizations.append(consumption)\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(WAITING_TIME)\n",
    "    time.sleep(BREAK_TIME)\n",
    "print(time.time() - start_time)\n",
    "\n",
    "# Create the dataframe and extract data from resources\n",
    "df_consumptions = pd.DataFrame(all_utilizations)\n",
    "df_consumptions['status'] = df_consumptions['current_state'].replace({'running': True, 'offline': False})\n",
    "df_consumptions['cpu'] = df_consumptions['resources'].apply(lambda x: x.get('cpu_absolute', None))\n",
    "df_consumptions['ram'] = df_consumptions['resources'].apply(lambda x: bytes_to_megabytes(x.get('memory_bytes', None)))\n",
    "df_consumptions['disk'] = df_consumptions['resources'].apply(lambda x: bytes_to_megabytes(x.get('disk_bytes', None)))\n",
    "df_consumptions['capture_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_consumptions = df_consumptions[['identifier', 'status', 'ram', 'cpu', 'disk', 'capture_time']]\n",
    "\n",
    "# Group by 'identifier' and calculate mean, std, min, and max for each group\n",
    "final_utilization_df = df_consumptions.groupby('identifier').agg({\n",
    "    'status': ['first'],  # Include 'current_state' in the aggregation\n",
    "    'ram': ['mean', 'std', 'min', 'max'],\n",
    "    'cpu': ['mean', 'std', 'min', 'max'],\n",
    "    'disk': ['mean', 'std', 'min', 'max'],\n",
    "    'capture_time': ['first']  \n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the column names\n",
    "final_utilization_df.columns = ['_'.join(col).strip() for col in final_utilization_df.columns.values]\n",
    "\n",
    "# Rename columns\n",
    "final_utilization_df = final_utilization_df.rename(columns={'identifier_': 'server_identifier'})\n",
    "final_utilization_df = final_utilization_df.rename(columns={'status_first': 'status'})\n",
    "final_utilization_df = final_utilization_df.rename(columns={'capture_time_first': 'capture_time'})\n",
    "print(final_utilization_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into Data Warehouse (Postgres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Schema and Table names in Postgres\n",
    "SCHEMA = 'pterodactyl'\n",
    "TABLE = 'utilization'\n",
    "\n",
    "# Connect to database and upload all new logs into table\n",
    "engine = create_engine(connection)\n",
    "with engine.connect() as conn:\n",
    "\n",
    "# Start a new transaction\n",
    "    trans = conn.begin()\n",
    "\n",
    "    try:\n",
    "        # Load all new activity into postgres\n",
    "        final_utilization_df.to_sql(name = TABLE, schema = SCHEMA, con = conn, if_exists='append', index=False)\n",
    "        # Commit the transaction\n",
    "        trans.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        # Rollback the transaction on exception\n",
    "        print('!!! [ERROR IN DATABASE QUERIES] !!!')\n",
    "        trans.rollback()\n",
    "        print('Transaction has been rolled back')\n",
    "        print(f'Error occurred during transaction:\\n{e}')\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
