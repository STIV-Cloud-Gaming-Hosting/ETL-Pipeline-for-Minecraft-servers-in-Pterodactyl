{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline for Pterodactyl Game Servers Logs\n",
    "\n",
    "### Index\n",
    "\n",
    "- Install requierements\n",
    "- Import libraries and setup key variables\n",
    "- Setup directories, functions and folder creation\n",
    "- Extract logs from each active Minecraft Server\n",
    "- Transformation from logs data into information\n",
    "- Load processed data into Data Warehouse (Postgres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requierements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and setup key variables\n",
    "Remember to add you own credentials in the .env file for them to be loaded here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, zipfile, requests, gzip, csv, os, re\n",
    "from sqlalchemy import create_engine, text\n",
    "from pydactyl import PterodactylClient\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "# Load .env file credentials\n",
    "load_dotenv()\n",
    "\n",
    "# Database connection\n",
    "host = os.getenv('POSTGRES_HOST')\n",
    "port = os.getenv('POSTGRES_PORT')\n",
    "database = os.getenv('POSTGRES_DATABASE')\n",
    "username = os.getenv('POSTGRES_USERNAME')\n",
    "password = os.getenv('POSTGRES_PASSWORD')\n",
    "connection = f'postgresql://{username}:{password}@{host}:{port}/{database}'\n",
    "\n",
    "# Pterodactyl connection\n",
    "pterodactyl_url = os.getenv('PTERODACTYL_URL')\n",
    "application_api_key = os.getenv('PTERODACTYL_APP_KEY')\n",
    "client_api_key = os.getenv('PTERODACTYL_CLI_KEY')\n",
    "\n",
    "# Connecto to Pterodactyl Application API\n",
    "api_app = PterodactylClient(pterodactyl_url, application_api_key, debug=False)\n",
    "# Connecto to Pterodactyl Client API\n",
    "api_cli = PterodactylClient(pterodactyl_url, client_api_key, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup directories, functions and folder creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up schema name in database\n",
    "schema = 'pterodactyl'\n",
    "minecraft_schema = 'minecraft'\n",
    "eggs_minecraft = ('Vanilla Minecraft', 'Forge Minecraft', 'Paper', 'Spigot', 'Mohist')\n",
    "eggs_ark = ('Ark: Survival Evolved',)\n",
    "all_eggs = eggs_minecraft + eggs_ark\n",
    "\n",
    "# Setup directories\n",
    "pwd = os.getcwd() #os.path.dirname(os.path.realpath(__file__)) this is used for .py files\n",
    "raw_logs_folder = os.path.join(pwd, 'raw_logs')\n",
    "\n",
    "# Dfine functions\n",
    "from functions import mkdir, sort_list_logs, last_index, extract_compressed_file, download_logs, transform_logs\n",
    "\n",
    "# Create folder if not exist\n",
    "mkdir(raw_logs_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract logs from each active Minecraft Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get server information from database\n",
    "engine = create_engine(connection)\n",
    "with engine.connect() as conn:\n",
    "    list_servers = conn.execute(text(f'SELECT servers.id, servers.identifier, eggs.name AS egg, last_log_date.last_date FROM {schema}.servers JOIN {schema}.eggs ON eggs.id = servers.egg_id LEFT JOIN {minecraft_schema}.last_log_date ON last_log_date.server_identifier = servers.identifier WHERE servers.is_active = true'))\n",
    "\n",
    "# Save server information from the query into a dataframe\n",
    "df_servers = pd.DataFrame(list_servers.fetchall(), columns=list_servers.keys())\n",
    "\n",
    "# Download the latest logs based on last_log and egg into the staging folder\n",
    "for server_info in df_servers.iterrows():\n",
    "    download_logs(id = server_info[1]['id'], identifier = server_info[1]['identifier'], egg = server_info[1]['egg'], last_log = server_info[1]['last_date'], staging_folder = raw_logs_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation from logs data to information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_logs = pd.DataFrame(columns=['server_id', 'date', 'time', 'information', 'user', 'activity'])\n",
    "\n",
    "for folder in os.listdir(raw_logs_folder): \n",
    "    folder_server_dir = os.path.join(raw_logs_folder, folder)\n",
    "\n",
    "    # \n",
    "    df_logs = transform_logs(id = folder, path_dir = folder_server_dir, df_servers = df_servers)\n",
    "    # Save every log in df_all_logs for each iteration\n",
    "    df_all_logs = pd.concat([df_all_logs, df_logs], ignore_index=True)\n",
    "\n",
    "    # Delete all logs inside each server folder\n",
    "    for folder in os.listdir(raw_logs_folder):\n",
    "        folder_server_dir = os.path.join(raw_logs_folder, folder)\n",
    "        [os.remove(os.path.join(folder_server_dir, log)) for log in os.listdir(folder_server_dir) if log.endswith('.log')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processed data into Data Warehouse (Postgres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set table name\n",
    "table = 'activity'\n",
    "\n",
    "# Connect to database and upload all new logs into table\n",
    "engine = create_engine(connection)\n",
    "with engine.connect() as conn:\n",
    "\n",
    "# Start a new transaction\n",
    "    trans = conn.begin()\n",
    "\n",
    "    try:\n",
    "        # Load all new activity into postgres\n",
    "        df_all_logs.to_sql(name = table, schema = schema, con = conn, if_exists='append', index=False)\n",
    "        # Commit the transaction\n",
    "        trans.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        # Rollback the transaction on exception\n",
    "        print('!!! [ERROR IN DATABASE QUERIES] !!!')\n",
    "        trans.rollback()\n",
    "        print('Transaction has been rolled back')\n",
    "        print(f'Error occurred during transaction:\\n{e}')\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
